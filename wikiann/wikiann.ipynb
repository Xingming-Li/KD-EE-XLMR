{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNNyQ3Hs3lGXsYrw2eDkXA1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtQqYKkkXFTI","executionInfo":{"status":"ok","timestamp":1758541352124,"user_tz":-120,"elapsed":19153,"user":{"displayName":"Xingming Li","userId":"09069172943603800000"}},"outputId":"892d67b2-fe82-4198-d163-4f9f4ab18ae5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install -r /content/drive/MyDrive/thesis/wikiann/requirements.txt  # For WikiANN\n","\n","# For correct version of transformers\n","!pip uninstall transformers -y\n","!pip install git+https://github.com/huggingface/transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1D2ovkGQXPyB","executionInfo":{"status":"ok","timestamp":1758541401781,"user_tz":-120,"elapsed":47632,"user":{"displayName":"Xingming Li","userId":"09069172943603800000"}},"outputId":"2e91de5f-64af-4139-a489-94370158a628"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (1.10.1)\n","Collecting seqeval (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 2))\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: datasets>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (4.0.0)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (2.8.0+cu126)\n","Collecting evaluate (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 5))\n","  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n","Collecting fvcore (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6))\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 7)) (0.6.2)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (25.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (6.0.2)\n","Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.12.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (0.34.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 2)) (1.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (3.19.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (3.4.0)\n","Collecting yacs>=0.1.6 (from fvcore->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6))\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6)) (11.3.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6)) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6))\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (3.12.15)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.12.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 1)) (1.1.9)\n","Collecting portalocker (from iopath>=0.1.7->fvcore->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 6))\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2025.8.3)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 2)) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 2)) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 2)) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 4)) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.8.0->-r /content/drive/MyDrive/thesis/wikiann/requirements.txt (line 3)) (1.17.0)\n","Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: seqeval, fvcore, iopath\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=1b46c0ecc2d8bc5a070d5415f310ae188dfc140edff1189dcf13bc40631e1e69\n","  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=8f40b9df355fcca6ff30ec63524ca618935769ca786480a16283d198e066f65d\n","  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=d9dff2524f7e731b0cb85dd23989aae9e33cbcb600f99263f230606e88ef56c2\n","  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n","Successfully built seqeval fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, seqeval, fvcore, evaluate\n","Successfully installed evaluate-0.4.6 fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 seqeval-1.2.2 yacs-0.1.8\n","Found existing installation: transformers 4.56.1\n","Uninstalling transformers-4.56.1:\n","  Successfully uninstalled transformers-4.56.1\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-8mit77vg\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-8mit77vg\n","  Resolved https://github.com/huggingface/transformers to commit 37152f84464dea9086dd1d88cd58f63c2129ee69\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (0.34.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (0.22.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (1.1.9)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (2025.8.3)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.57.0.dev0-py3-none-any.whl size=11476855 sha256=47d067de88e2beb2cc4a2af1e26e7d47f62a1bea4004e2bf88e87ec702c92215\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fo3tqv7h/wheels/49/a7/50/c9fdabbf10e51bb1256adb0c1a587fedd7184f5bad28d47fe3\n","Successfully built transformers\n","Installing collected packages: transformers\n","Successfully installed transformers-4.57.0.dev0\n"]}]},{"cell_type":"code","source":["# Fine-tuning\n","!python /content/drive/MyDrive/thesis/wikiann/run_ner_eff.py \\\n","  --model_name_or_path /content/drive/MyDrive/thesis/distilled_models/l7/e1 \\\n","  --dataset_name wikiann \\\n","  --dataset_config_name en \\\n","  --output_dir /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/ \\\n","  --do_train \\\n","  --save_steps -1 \\\n","  --learning_rate 5e-5 \\\n","  --early_exit True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZxfYCmrXfe3","executionInfo":{"status":"ok","timestamp":1758541976082,"user_tz":-120,"elapsed":378682,"user":{"displayName":"Xingming Li","userId":"09069172943603800000"}},"outputId":"32ca2e56-a019-44ba-a9f2-3bcaa622a12a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=True,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=False,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=IntervalStrategy.NO,\n","eval_use_gather_object=False,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_revision=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=no,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","liger_kernel_config=None,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/runs/Sep22_11-46-41_dd30e65a5f57,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=OptimizerNames.ADAMW_TORCH_FUSED,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=/content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/,\n","overwrite_output_dir=False,\n","parallelism_config=None,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=None,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=-1.0,\n","save_strategy=SaveStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","`trust_remote_code` is not supported anymore.\n","Please check that the Hugging Face dataset 'wikiann' isn't based on a loading script and remove `trust_remote_code`.\n","If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n","ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n","Please check that the Hugging Face dataset 'wikiann' isn't based on a loading script and remove `trust_remote_code`.\n","If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n","Found cached dataset wikiann (/root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4)\n","INFO:datasets.builder:Found cached dataset wikiann (/root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4)\n","[INFO|configuration_utils.py:757] 2025-09-22 11:46:45,399 >> loading configuration file /content/drive/MyDrive/thesis/distilled_models/l7/e1/config.json\n","[INFO|configuration_utils.py:833] 2025-09-22 11:46:45,401 >> Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRobertaModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"dtype\": \"float32\",\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"ner\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.57.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 11:46:45,413 >> loading file sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 11:46:45,414 >> loading file tokenizer.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 11:46:45,414 >> loading file added_tokens.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 11:46:45,414 >> loading file special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 11:46:45,414 >> loading file tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 11:46:45,414 >> loading file chat_template.jinja\n","[INFO|configuration_utils.py:757] 2025-09-22 11:46:47,700 >> loading configuration file /content/drive/MyDrive/thesis/distilled_models/l7/e1/config.json\n","[INFO|configuration_utils.py:833] 2025-09-22 11:46:47,701 >> Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRobertaModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"dtype\": \"float32\",\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.57.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","[INFO|modeling_utils.py:1202] 2025-09-22 11:46:47,717 >> loading weights file /content/drive/MyDrive/thesis/distilled_models/l7/e1/model.safetensors\n","[INFO|modeling_utils.py:5574] 2025-09-22 11:46:47,908 >> All model checkpoint weights were used when initializing XLMRobertaModel.\n","\n","[INFO|modeling_utils.py:5582] 2025-09-22 11:46:47,908 >> All the weights of XLMRobertaModel were initialized from the model checkpoint at /content/drive/MyDrive/thesis/distilled_models/l7/e1.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaModel for predictions without further training.\n","WARNING:__main__:⚠️ No exit_heads found, using random initialization\n","WARNING:__main__:Your model seems to have been trained with labels, but they don't match the dataset: model labels: ['LABEL_0', 'LABEL_1'], dataset labels: ['B-LOC', 'B-ORG', 'B-PER', 'I-LOC', 'I-ORG', 'I-PER', 'O'].\n","Ignoring the model labels as a result.\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4/cache-5c3c33aa7dee1b42_*_of_00001.arrow\n","INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4/cache-5c3c33aa7dee1b42_*_of_00001.arrow\n","2025-09-22 11:46:49.290912: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-09-22 11:46:49.306361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758541609.324264    7274 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758541609.329561    7274 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1758541609.343400    7274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1758541609.343423    7274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1758541609.343426    7274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1758541609.343428    7274 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-09-22 11:46:49.347498: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","[INFO|trainer.py:1012] 2025-09-22 11:46:52,225 >> The following columns in the Training set don't have a corresponding argument in `XLMRWithEarlyExit.forward` and have been ignored: spans, tokens, langs, ner_tags. If spans, tokens, langs, ner_tags are not expected by `XLMRWithEarlyExit.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2519] 2025-09-22 11:46:52,242 >> ***** Running training *****\n","[INFO|trainer.py:2520] 2025-09-22 11:46:52,242 >>   Num examples = 20,000\n","[INFO|trainer.py:2521] 2025-09-22 11:46:52,242 >>   Num Epochs = 3\n","[INFO|trainer.py:2522] 2025-09-22 11:46:52,242 >>   Instantaneous batch size per device = 8\n","[INFO|trainer.py:2525] 2025-09-22 11:46:52,242 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2526] 2025-09-22 11:46:52,242 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2527] 2025-09-22 11:46:52,242 >>   Total optimization steps = 7,500\n","[INFO|trainer.py:2528] 2025-09-22 11:46:52,243 >>   Number of trainable parameters = 278,054,414\n","[INFO|integration_utils.py:860] 2025-09-22 11:46:52,265 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdamianxml\u001b[0m (\u001b[33mdamianxml-uppsala-universitet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250922_114736-dr5ttcns\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-resonance-265\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/damianxml-uppsala-universitet/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/damianxml-uppsala-universitet/huggingface/runs/dr5ttcns\u001b[0m\n","{'loss': 0.6377, 'grad_norm': 11.576092720031738, 'learning_rate': 4.667333333333333e-05, 'epoch': 0.2}\n","{'loss': 0.4218, 'grad_norm': 12.288365364074707, 'learning_rate': 4.334e-05, 'epoch': 0.4}\n","{'loss': 0.3854, 'grad_norm': 3.3132712841033936, 'learning_rate': 4.000666666666667e-05, 'epoch': 0.6}\n","{'loss': 0.3709, 'grad_norm': 4.118844509124756, 'learning_rate': 3.667333333333334e-05, 'epoch': 0.8}\n","{'loss': 0.34, 'grad_norm': 3.5112643241882324, 'learning_rate': 3.3339999999999996e-05, 'epoch': 1.0}\n","{'loss': 0.2738, 'grad_norm': 7.0932488441467285, 'learning_rate': 3.0006666666666665e-05, 'epoch': 1.2}\n","{'loss': 0.2555, 'grad_norm': 10.11365795135498, 'learning_rate': 2.6673333333333334e-05, 'epoch': 1.4}\n","{'loss': 0.2588, 'grad_norm': 9.007950782775879, 'learning_rate': 2.334e-05, 'epoch': 1.6}\n","{'loss': 0.2512, 'grad_norm': 3.1878983974456787, 'learning_rate': 2.000666666666667e-05, 'epoch': 1.8}\n","{'loss': 0.2503, 'grad_norm': 12.360958099365234, 'learning_rate': 1.6673333333333335e-05, 'epoch': 2.0}\n","{'loss': 0.1802, 'grad_norm': 4.234018802642822, 'learning_rate': 1.334e-05, 'epoch': 2.2}\n","{'loss': 0.1899, 'grad_norm': 2.4253134727478027, 'learning_rate': 1.0006666666666667e-05, 'epoch': 2.4}\n","{'loss': 0.1775, 'grad_norm': 3.7481513023376465, 'learning_rate': 6.673333333333334e-06, 'epoch': 2.6}\n","{'loss': 0.172, 'grad_norm': 0.6947749257087708, 'learning_rate': 3.34e-06, 'epoch': 2.8}\n","{'loss': 0.1723, 'grad_norm': 9.515201568603516, 'learning_rate': 6.666666666666668e-09, 'epoch': 3.0}\n","100% 7500/7500 [04:54<00:00, 25.35it/s][INFO|trainer.py:4311] 2025-09-22 11:52:32,589 >> Saving model checkpoint to /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/checkpoint-7500\n","[INFO|configuration_utils.py:485] 2025-09-22 11:52:32,604 >> Configuration saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/checkpoint-7500/config.json\n","[INFO|modeling_utils.py:4209] 2025-09-22 11:52:35,550 >> Model weights saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/checkpoint-7500/model.safetensors\n","[INFO|tokenization_utils_base.py:2554] 2025-09-22 11:52:35,556 >> tokenizer config file saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2563] 2025-09-22 11:52:35,560 >> Special tokens file saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/checkpoint-7500/special_tokens_map.json\n","[INFO|trainer.py:2810] 2025-09-22 11:52:42,821 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 350.578, 'train_samples_per_second': 171.146, 'train_steps_per_second': 21.393, 'train_loss': 0.289166401163737, 'epoch': 3.0}\n","100% 7500/7500 [05:05<00:00, 24.58it/s]\n","[INFO|trainer.py:4311] 2025-09-22 11:52:42,827 >> Saving model checkpoint to /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/\n","[INFO|configuration_utils.py:485] 2025-09-22 11:52:42,833 >> Configuration saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/config.json\n","[INFO|modeling_utils.py:4209] 2025-09-22 11:52:48,221 >> Model weights saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/model.safetensors\n","[INFO|tokenization_utils_base.py:2554] 2025-09-22 11:52:51,434 >> tokenizer config file saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2563] 2025-09-22 11:52:51,440 >> Special tokens file saved in /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/special_tokens_map.json\n","INFO:__main__:✅ Saved exit_heads to /content/drive/MyDrive/thesis/wikiann/distilled/l7_ft/e1_ee_al_test/exit_heads.bin\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   799192GF\n","  train_loss               =     0.2892\n","  train_runtime            = 0:05:50.57\n","  train_samples            =      20000\n","  train_samples_per_second =    171.146\n","  train_steps_per_second   =     21.393\n","[INFO|modelcard.py:450] 2025-09-22 11:52:51,565 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'dataset': {'name': 'wikiann en', 'type': 'wikiann', 'args': 'en'}}\n","\u001b[1;34mwandb\u001b[0m: \n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mdandy-resonance-265\u001b[0m at: \u001b[34mhttps://wandb.ai/damianxml-uppsala-universitet/huggingface/runs/dr5ttcns\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250922_114736-dr5ttcns/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["# Evaluation\n","!python /content/drive/MyDrive/thesis/wikiann/restructured_run_ner_eff.py \\\n","  --model_name_or_path /content/drive/MyDrive/thesis/wikiann/distilled/l12_ft/e5_ee \\\n","  --dataset_name wikiann \\\n","  --dataset_config_name en \\\n","  --output_dir /content/drive/MyDrive/thesis/wikiann/distilled/l12_eval/en_test \\\n","  --do_eval \\\n","  --max_eval_samples 1000 \\\n","  --max_seq_length 128 \\\n","  --early_exit True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2hGsJyCbMXr","executionInfo":{"status":"ok","timestamp":1758544004999,"user_tz":-120,"elapsed":26476,"user":{"displayName":"Xingming Li","userId":"09069172943603800000"}},"outputId":"6f3121a9-b8bb-4957-bdc0-b94c3693b66c"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=True,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=IntervalStrategy.NO,\n","eval_use_gather_object=False,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_revision=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=no,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","liger_kernel_config=None,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/thesis/wikiann/distilled/l12_eval/en_test/runs/Sep22_12-26-23_dd30e65a5f57,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=OptimizerNames.ADAMW_TORCH_FUSED,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=/content/drive/MyDrive/thesis/wikiann/distilled/l12_eval/en_test,\n","overwrite_output_dir=False,\n","parallelism_config=None,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=None,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=SaveStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","`trust_remote_code` is not supported anymore.\n","Please check that the Hugging Face dataset 'wikiann' isn't based on a loading script and remove `trust_remote_code`.\n","If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n","ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n","Please check that the Hugging Face dataset 'wikiann' isn't based on a loading script and remove `trust_remote_code`.\n","If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n","Found cached dataset wikiann (/root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4)\n","INFO:datasets.builder:Found cached dataset wikiann (/root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4)\n","[INFO|configuration_utils.py:757] 2025-09-22 12:26:26,860 >> loading configuration file /content/drive/MyDrive/thesis/wikiann/distilled/l12_ft/e5_ee/config.json\n","[INFO|configuration_utils.py:833] 2025-09-22 12:26:26,862 >> Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRWithEarlyExit\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"dtype\": \"float32\",\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"ner\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"B-PER\",\n","    \"2\": \"I-PER\",\n","    \"3\": \"B-ORG\",\n","    \"4\": \"I-ORG\",\n","    \"5\": \"B-LOC\",\n","    \"6\": \"I-LOC\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-LOC\": 5,\n","    \"B-ORG\": 3,\n","    \"B-PER\": 1,\n","    \"I-LOC\": 6,\n","    \"I-ORG\": 4,\n","    \"I-PER\": 2,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.57.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 12:26:26,875 >> loading file sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 12:26:26,875 >> loading file tokenizer.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 12:26:26,875 >> loading file added_tokens.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 12:26:26,876 >> loading file special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 12:26:26,876 >> loading file tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2057] 2025-09-22 12:26:26,876 >> loading file chat_template.jinja\n","[INFO|configuration_utils.py:757] 2025-09-22 12:26:27,523 >> loading configuration file /content/drive/MyDrive/thesis/wikiann/distilled/l12_ft/e5_ee/config.json\n","[INFO|configuration_utils.py:833] 2025-09-22 12:26:27,524 >> Model config XLMRobertaConfig {\n","  \"architectures\": [\n","    \"XLMRWithEarlyExit\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"dtype\": \"float32\",\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"O\",\n","    \"1\": \"B-PER\",\n","    \"2\": \"I-PER\",\n","    \"3\": \"B-ORG\",\n","    \"4\": \"I-ORG\",\n","    \"5\": \"B-LOC\",\n","    \"6\": \"I-LOC\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"B-LOC\": 5,\n","    \"B-ORG\": 3,\n","    \"B-PER\": 1,\n","    \"I-LOC\": 6,\n","    \"I-ORG\": 4,\n","    \"I-PER\": 2,\n","    \"O\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.57.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","[INFO|modeling_utils.py:2380] 2025-09-22 12:26:27,538 >> Instantiating XLMRobertaModel model under default dtype torch.float32.\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4/cache-bd68e9280130bd6a_*_of_00001.arrow\n","INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/wikiann/en/0.0.0/f0a3be6dc5564c0cc4150bb660144800a1f539d4/cache-bd68e9280130bd6a_*_of_00001.arrow\n","2025-09-22 12:26:32.863582: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2025-09-22 12:26:32.879508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1758543992.897609   18960 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1758543992.903070   18960 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1758543992.917114   18960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1758543992.917138   18960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1758543992.917141   18960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1758543992.917144   18960 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-09-22 12:26:32.921234: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:1012] 2025-09-22 12:26:35,829 >> The following columns in the Evaluation set don't have a corresponding argument in `XLMRWithEarlyExit.forward` and have been ignored: spans, tokens, langs, ner_tags. If spans, tokens, langs, ner_tags are not expected by `XLMRWithEarlyExit.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:4645] 2025-09-22 12:26:35,841 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4647] 2025-09-22 12:26:35,841 >>   Num examples = 1000\n","[INFO|trainer.py:4650] 2025-09-22 12:26:35,841 >>   Batch size = 8\n"," 96% 120/125 [00:01<00:00, 73.94it/s]predictions shape: (1000, 128, 7)\n","[INFO|integration_utils.py:860] 2025-09-22 12:26:37,967 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdamianxml\u001b[0m (\u001b[33mdamianxml-uppsala-universitet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250922_122638-rfv7vfbe\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msoft-bee-275\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/damianxml-uppsala-universitet/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/damianxml-uppsala-universitet/huggingface/runs/rfv7vfbe\u001b[0m\n","100% 125/125 [00:03<00:00, 39.28it/s]\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::ne encountered 1 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::cumsum encountered 1 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 27 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 9 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::embedding encountered 3 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 1 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sub encountered 1 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::softmax encountered 8 time(s)\n","WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::gelu encountered 8 time(s)\n","WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n","model.backbone.encoder.layer.0.attention.self.dropout, model.backbone.encoder.layer.1.attention.self.dropout, model.backbone.encoder.layer.10, model.backbone.encoder.layer.10.attention, model.backbone.encoder.layer.10.attention.output, model.backbone.encoder.layer.10.attention.output.LayerNorm, model.backbone.encoder.layer.10.attention.output.dense, model.backbone.encoder.layer.10.attention.output.dropout, model.backbone.encoder.layer.10.attention.self, model.backbone.encoder.layer.10.attention.self.dropout, model.backbone.encoder.layer.10.attention.self.key, model.backbone.encoder.layer.10.attention.self.query, model.backbone.encoder.layer.10.attention.self.value, model.backbone.encoder.layer.10.intermediate, model.backbone.encoder.layer.10.intermediate.dense, model.backbone.encoder.layer.10.intermediate.intermediate_act_fn, model.backbone.encoder.layer.10.output, model.backbone.encoder.layer.10.output.LayerNorm, model.backbone.encoder.layer.10.output.dense, model.backbone.encoder.layer.10.output.dropout, model.backbone.encoder.layer.11, model.backbone.encoder.layer.11.attention, model.backbone.encoder.layer.11.attention.output, model.backbone.encoder.layer.11.attention.output.LayerNorm, model.backbone.encoder.layer.11.attention.output.dense, model.backbone.encoder.layer.11.attention.output.dropout, model.backbone.encoder.layer.11.attention.self, model.backbone.encoder.layer.11.attention.self.dropout, model.backbone.encoder.layer.11.attention.self.key, model.backbone.encoder.layer.11.attention.self.query, model.backbone.encoder.layer.11.attention.self.value, model.backbone.encoder.layer.11.intermediate, model.backbone.encoder.layer.11.intermediate.dense, model.backbone.encoder.layer.11.intermediate.intermediate_act_fn, model.backbone.encoder.layer.11.output, model.backbone.encoder.layer.11.output.LayerNorm, model.backbone.encoder.layer.11.output.dense, model.backbone.encoder.layer.11.output.dropout, model.backbone.encoder.layer.2.attention.self.dropout, model.backbone.encoder.layer.3.attention.self.dropout, model.backbone.encoder.layer.4.attention.self.dropout, model.backbone.encoder.layer.5.attention.self.dropout, model.backbone.encoder.layer.6.attention.self.dropout, model.backbone.encoder.layer.7.attention.self.dropout, model.backbone.encoder.layer.8, model.backbone.encoder.layer.8.attention, model.backbone.encoder.layer.8.attention.output, model.backbone.encoder.layer.8.attention.output.LayerNorm, model.backbone.encoder.layer.8.attention.output.dense, model.backbone.encoder.layer.8.attention.output.dropout, model.backbone.encoder.layer.8.attention.self, model.backbone.encoder.layer.8.attention.self.dropout, model.backbone.encoder.layer.8.attention.self.key, model.backbone.encoder.layer.8.attention.self.query, model.backbone.encoder.layer.8.attention.self.value, model.backbone.encoder.layer.8.intermediate, model.backbone.encoder.layer.8.intermediate.dense, model.backbone.encoder.layer.8.intermediate.intermediate_act_fn, model.backbone.encoder.layer.8.output, model.backbone.encoder.layer.8.output.LayerNorm, model.backbone.encoder.layer.8.output.dense, model.backbone.encoder.layer.8.output.dropout, model.backbone.encoder.layer.9, model.backbone.encoder.layer.9.attention, model.backbone.encoder.layer.9.attention.output, model.backbone.encoder.layer.9.attention.output.LayerNorm, model.backbone.encoder.layer.9.attention.output.dense, model.backbone.encoder.layer.9.attention.output.dropout, model.backbone.encoder.layer.9.attention.self, model.backbone.encoder.layer.9.attention.self.dropout, model.backbone.encoder.layer.9.attention.self.key, model.backbone.encoder.layer.9.attention.self.query, model.backbone.encoder.layer.9.attention.self.value, model.backbone.encoder.layer.9.intermediate, model.backbone.encoder.layer.9.intermediate.dense, model.backbone.encoder.layer.9.intermediate.intermediate_act_fn, model.backbone.encoder.layer.9.output, model.backbone.encoder.layer.9.output.LayerNorm, model.backbone.encoder.layer.9.output.dense, model.backbone.encoder.layer.9.output.dropout, model.backbone.pooler, model.backbone.pooler.activation, model.backbone.pooler.dense, model.exit_heads.4\n","***** eval metrics *****\n","  avg_inference_time_sec      =     0.0111\n","  eval_accuracy               =     0.9227\n","  eval_f1                     =      0.794\n","  eval_loss                   =     1.2896\n","  eval_model_preparation_time =     0.0029\n","  eval_precision              =     0.7843\n","  eval_recall                 =     0.8039\n","  eval_runtime                = 0:00:02.12\n","  eval_samples                =       1000\n","  eval_samples_per_second     =    471.705\n","  eval_steps_per_second       =     58.963\n","  flops_giga                  =       7.46\n","  peak_memory_GB              =      1.053\n","[INFO|modelcard.py:450] 2025-09-22 12:26:40,652 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'dataset': {'name': 'wikiann en', 'type': 'wikiann', 'args': 'en'}}\n","\u001b[1;34mwandb\u001b[0m: \n","\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33msoft-bee-275\u001b[0m at: \u001b[34mhttps://wandb.ai/damianxml-uppsala-universitet/huggingface/runs/rfv7vfbe\u001b[0m\n","\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250922_122638-rfv7vfbe/logs\u001b[0m\n"]}]}]}